Paper Name,Authors,Link,Abstract,Venue,Year,type
"Accelerating 3D Scene Development for the
Metaverse: Lessons from Photogrammetry and
Manual Modeling","Viviana Pentangelo, Dario Di Dario, Vincenzo De Martino, Marco Dello Buono, Stefano Lambiase",https://vipenti.github.io/assets/docs/iMeta_Accelerating.pdf,"The metaverse, a 3D immersive digital environment, is gaining significant interest due to its ability to connect people globally engaging and immersively, thanks to recent technological advancements. Developing high-quality 3D models is crucial for achieving realism and immersivity in the metaverse. However, this process is complex and resource-intensive, demanding specialized skills and substantial time. The emergence of novel automation tools and technologies, such as photogrammetry, which uses computer vision algorithms to reconstruct 3D models from 2D images, is beginning to address such challenges. Our research focused on analyzing the current state of such technologies in automating 3D scenes for the metaverse, comparing them to traditional manual modeling techniques. We conducted an experiment in which we built the same 3D scene using two techniques: a manual approach with Blender and a photogrammetry approach exploiting the Polycam tool on a mobile device. Our results have provided insights into the main strengths and limitations of using 3D automation techniques. The photogrammetry approach has significantly sped up the entire process, producing textures and models that accurately replicate real objects. However, it cannot wholly replace manual modeling approaches, without which it is impossible to obtain complete and efficient models. Lessons learned will serve as a foundation to guide developers in developing 3D scenes for the metaverse.",Proceedings of the 2nd International Conference on Intelligent Metaverse Technologies & Applications (iMETA 2024),2024,conference
Classification and Challenges of Non-Functional Requirements in ML-Enabled Systems: A Systematic Literature Review,"Vincenzo De Martino, Fabio Palomba",assets/docs/slr.pdf,"Context: Machine learning (ML) is nowadays so pervasive and diffused that virtually no application can avoid its use. Nonetheless, its enormous potential is often tempered by the need to manage non-functional requirements (NFRs) and navigate pressing, contrasting trade-offs.
Objective: In this respect, we notice a lack of systematic synthesis of challenges explicitly tied to achieving and managing NFRs in ML-enabled systems. Such a synthesis may not only provide a comprehensive summary of the state of the art but also drive further research on the analysis, management, and optimization of NFRs of ML-enabled systems.
Method: In this paper, we propose a systematic literature review targeting two key aspects such as (1) the classification of the NFRs investigated so far, and (2) the challenges associated with achieving and managing NFRs in ML-enabled systems during model development
Through the combination of well-established guidelines for conducting systematic literature reviews and additional search criteria, we survey a total amount of 130 research articles.
Results: Our findings report that current research identified 31 different NFRs, which can be grouped into six main classes.
We also compiled a catalog of 26 software engineering challenges, emphasizing the need for further research to systematically address, prioritize, and balance NFRs in ML-enabled systems.
Conclusion: We conclude our work by distilling implications and a future outlook on the topic.",Elsevier's Journal of Information and Software Technology (IST),2025,journal
Do Developers Adopt Green Architectural Tactics for ML-Enabled Systems? A Mining Software Repository Study,"Vincenzo De Martino, Silverio Martínez-Fernández, Fabio Palomba",https://arxiv.org/pdf/2410.06708,"As machine learning (ML) and artificial intelligence (AI) technologies become more widespread, concerns about their environmental impact are increasing due to the resource-intensive nature of training and inference processes. Green AI advocates for reducing computational demands while still maintaining accuracy. Although various strategies for creating sustainable ML systems have been identified, their real-world implementation is still underexplored.
This paper addresses this gap by studying 168 open-source ML projects on GitHub. It employs a novel large language model (LLM)-based mining mechanism to identify and analyze green strategies. The findings reveal the adoption of established tactics that offer significant environmental benefits. This provides practical insights for developers and paves the way for future automation of sustainable practices in ML systems.",2025 IEEE/ACM 47th International Conference on Software Engineering: Software Engineering in Society (ICSE-SEIS),2025,conference
A Framework for Using LLMs for Repository Mining Studies in Empirical Software Engineering,"Vincenzo De Martino, Joel Castaño, Fabio Palomba, Xavier Franch, Silverio Martínez-Fernández",https://arxiv.org/pdf/2411.09974,"Context: The emergence of Large Language Models (LLMs) has significantly transformed Software Engineering (SE) by providing innovative methods for analyzing software repositories. Objectives: Our objective is to establish a practical framework for future SE researchers needing to enhance the data collection and dataset while conducting software repository mining studies using LLMs. Method: This experience report shares insights from two previous repository mining studies, focusing on the methodologies used for creating, refining, and validating prompts that enhance the output of LLMs, particularly in the context of data collection in empirical studies. Results: Our research packages a framework, coined Prompt Refinement and Insights for Mining Empirical Software repositories (PRIMES), consisting of a checklist that can improve LLM usage performance, enhance output quality, and minimize errors through iterative processes and comparisons among different LLMs. We also emphasize the significance of reproducibility by implementing mechanisms for tracking model results. Conclusion: Our findings indicate that standardizing prompt engineering and using PRIMES can enhance the reliability and reproducibility of studies utilizing LLMs. Ultimately, this work calls for further research to address challenges like hallucinations, model biases, and cost-effectiveness in integrating LLMs into workflows.",2nd International Workshop on Methodological Issues with Empirical Studies in Software Engineering (WSESE 2025),2025,workshop
Preliminary Analysis on the Evolution of Self-Admitted Technical Debt in ML-enabled Systems,"Gilberto Recupito, Vincenzo De Martino, Dario Di Nucci, Fabio Palomba",assets/docs/satd.pdf,"The rapid adoption of Deep Learning (DL)-enabled systems has revolutionized software development, driving innovation across various domains. However, these systems also introduce unique challenges, particularly in maintaining software quality and performance. Among these challenges, Self-Admitted Technical Debt (SATD) has emerged as a growing concern, significantly impacting the maintainability and overall quality of ML and DL-enabled systems. Despite its critical implications, the lifecycle of DL-specific SATD—how developers introduce, acknowledge, and address it over time—remains underexplored.
This study presents a preliminary analysis of the persistence and lifecycle of DL-specific SATD in DL-enabled systems. The purpose of this project is to uncover the patterns of SATD introduction, recognition, and durability during the development life cycle, providing information on how to manage these issues. Using mining software repository techniques, we examined 40 ML projects, focusing on 185 DL-specific SATD instances. The analysis tracked the introduction and persistence of SATD instances through project commit histories to assess their lifecycle and developer actions. The findings indicate that DL-specific SATD is predominantly introduced during the early and middle stages of project development. Training and Hardware phases showed the longest SATD durations, highlighting critical areas where debt accumulates and persists. Additionally, developers introduce DL-specific SATD more frequently during feature implementation and bug fixes. This study emphasizes the need for targeted DL-specific SATD management strategies in DL-enabled systems to mitigate its impact. By understanding the temporal characteristics and evolution of DL-specific SATD, developers can prioritize interventions at critical stages to improve the maintainability and quality of the system.",2nd Workshop on Software Quality Assurance for Artificial Intelligence ,2025,workshop