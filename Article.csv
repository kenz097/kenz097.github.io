Paper Name,Authors,Link,Abstract,Venue,Year,type,AddedDate
"Accelerating 3D Scene Development for the
Metaverse: Lessons from Photogrammetry and
Manual Modeling","Viviana Pentangelo, Dario Di Dario, Vincenzo De Martino, Marco Dello Buono, Stefano Lambiase",assets/docs/conference/c1.pdf,"The metaverse, a 3D immersive digital environment, is gaining significant interest due to its ability to connect people globally engaging and immersively, thanks to recent technological advancements. Developing high-quality 3D models is crucial for achieving realism and immersivity in the metaverse. However, this process is complex and resource-intensive, demanding specialized skills and substantial time. The emergence of novel automation tools and technologies, such as photogrammetry, which uses computer vision algorithms to reconstruct 3D models from 2D images, is beginning to address such challenges. Our research focused on analyzing the current state of such technologies in automating 3D scenes for the metaverse, comparing them to traditional manual modeling techniques. We conducted an experiment in which we built the same 3D scene using two techniques: a manual approach with Blender and a photogrammetry approach exploiting the Polycam tool on a mobile device. Our results have provided insights into the main strengths and limitations of using 3D automation techniques. The photogrammetry approach has significantly sped up the entire process, producing textures and models that accurately replicate real objects. However, it cannot wholly replace manual modeling approaches, without which it is impossible to obtain complete and efficient models. Lessons learned will serve as a foundation to guide developers in developing 3D scenes for the metaverse.","Proceedings of the 2nd International Conference on Intelligent Metaverse Technologies & Applications (iMETA), Dubai, UAE",2024,conference,01/09/2024
Classification and Challenges of Non-Functional Requirements in ML-Enabled Systems: A Systematic Literature Review,"Vincenzo De Martino, Fabio Palomba",assets/docs/journal/j1.pdf,"Context: Machine learning (ML) is nowadays so pervasive and diffused that virtually no application can avoid its use. Nonetheless, its enormous potential is often tempered by the need to manage non-functional requirements (NFRs) and navigate pressing, contrasting trade-offs.
Objective: In this respect, we notice a lack of systematic synthesis of challenges explicitly tied to achieving and managing NFRs in ML-enabled systems. Such a synthesis may not only provide a comprehensive summary of the state of the art but also drive further research on the analysis, management, and optimization of NFRs of ML-enabled systems.
Method: In this paper, we propose a systematic literature review targeting two key aspects such as (1) the classification of the NFRs investigated so far, and (2) the challenges associated with achieving and managing NFRs in ML-enabled systems during model development
Through the combination of well-established guidelines for conducting systematic literature reviews and additional search criteria, we survey a total amount of 130 research articles.
Results: Our findings report that current research identified 31 different NFRs, which can be grouped into six main classes.
We also compiled a catalog of 26 software engineering challenges, emphasizing the need for further research to systematically address, prioritize, and balance NFRs in ML-enabled systems.
Conclusion: We conclude our work by distilling implications and a future outlook on the topic.",Elsevier's Journal of Information and Software Technology (IST),2025,journal,28/01/2025
Do Developers Adopt Green Architectural Tactics for ML-Enabled Systems? A Mining Software Repository Study,"Vincenzo De Martino, Silverio Martínez-Fernández, Fabio Palomba",assets/docs/conference/c3.pdf,"As machine learning (ML) and artificial intelligence (AI) technologies become more widespread, concerns about their environmental impact are increasing due to the resource-intensive nature of training and inference processes. Green AI advocates for reducing computational demands while still maintaining accuracy. Although various strategies for creating sustainable ML systems have been identified, their real-world implementation is still underexplored.
This paper addresses this gap by studying 168 open-source ML projects on GitHub. It employs a novel large language model (LLM)-based mining mechanism to identify and analyze green strategies. The findings reveal the adoption of established tactics that offer significant environmental benefits. This provides practical insights for developers and paves the way for future automation of sustainable practices in ML systems.","IEEE/ACM 47th International Conference on Software Engineering: Software Engineering in Society (ICSE-SEIS), Ottawa, Canada",2025,conference,10/01/2025
A Framework for Using LLMs for Repository Mining Studies in Empirical Software Engineering,"Vincenzo De Martino, Joel Castaño, Fabio Palomba, Xavier Franch, Silverio Martínez-Fernández",assets/docs/workshop/w3.pdf,"Context: The emergence of Large Language Models (LLMs) has significantly transformed Software Engineering (SE) by providing innovative methods for analyzing software repositories. Objectives: Our objective is to establish a practical framework for future SE researchers needing to enhance the data collection and dataset while conducting software repository mining studies using LLMs. Method: This experience report shares insights from two previous repository mining studies, focusing on the methodologies used for creating, refining, and validating prompts that enhance the output of LLMs, particularly in the context of data collection in empirical studies. Results: Our research packages a framework, coined Prompt Refinement and Insights for Mining Empirical Software repositories (PRIMES), consisting of a checklist that can improve LLM usage performance, enhance output quality, and minimize errors through iterative processes and comparisons among different LLMs. We also emphasize the significance of reproducibility by implementing mechanisms for tracking model results. Conclusion: Our findings indicate that standardizing prompt engineering and using PRIMES can enhance the reliability and reproducibility of studies utilizing LLMs. Ultimately, this work calls for further research to address challenges like hallucinations, model biases, and cost-effectiveness in integrating LLMs into workflows.","2nd International Workshop on Methodological Issues with Empirical Studies in Software Engineering (WSESE - co-located with ICSE), Ottawa, Canada",2025,workshop,01/11/2024
A First Look at the Lifecycle of DL-Specific Self-Admitted Technical Debt,"Gilberto Recupito, Vincenzo De Martino, Dario Di Nucci, Fabio Palomba",assets/docs/workshop/w4.pdf,"The rapid adoption of Deep Learning (DL)-enabled systems has revolutionized software development, driving innovation across various domains. However, these systems also introduce unique challenges, particularly in maintaining software quality and performance. Among these challenges, Self-Admitted Technical Debt (SATD) has emerged as a growing concern, significantly impacting the maintainability and overall quality of ML and DL-enabled systems. Despite its critical implications, the lifecycle of DL-specific SATD—how developers introduce, acknowledge, and address it over time—remains underexplored.
This study presents a preliminary analysis of the persistence and lifecycle of DL-specific SATD in DL-enabled systems. The purpose of this project is to uncover the patterns of SATD introduction, recognition, and durability during the development life cycle, providing information on how to manage these issues. Using mining software repository techniques, we examined 40 ML projects, focusing on 185 DL-specific SATD instances. The analysis tracked the introduction and persistence of SATD instances through project commit histories to assess their lifecycle and developer actions. The findings indicate that DL-specific SATD is predominantly introduced during the early and middle stages of project development. Training and Hardware phases showed the longest SATD durations, highlighting critical areas where debt accumulates and persists. Additionally, developers introduce DL-specific SATD more frequently during feature implementation and bug fixes. This study emphasizes the need for targeted DL-specific SATD management strategies in DL-enabled systems to mitigate its impact. By understanding the temporal characteristics and evolution of DL-specific SATD, developers can prioritize interventions at critical stages to improve the maintainability and quality of the system.","2nd Workshop on Software Quality Assurance for Artificial Intelligence (SQA4AI - co-located with SANER), Montréal, Canada",2025,workshop,01/01/2025
Examining the Impact of Bias Mitigation Algorithms on the Sustainability of ML-enabled Systems: A Benchmark Study,"Vincenzo De Martino, Gianmario Voria, Ciro Troiano, Gemma Catolino, Fabio Palomba",assets/docs/journal/j2.pdf,"Context: As machine learning (ML) systems become increasingly prevalent across various industries, concerns regarding fairness have intensified. Bias mitigation algorithms---that aim to reduce bias in ML models---serve as solutions to mitigate this issue. However, these techniques can affect more than just social sustainability. They may alter the computational overhead and energy usage of ML systems, affecting their environmental sustainability. Similarly, they can influence businesses' economic sustainability by shaping resource allocation and consumer trust. Goal: This work aims to provide a benchmark study of the implications of applying bias mitigation algorithms on the sustainability of ML solutions. We first corroborate previous findings by examining their effect on social sustainability metrics. Additionally, we complement existing studies by offering a comprehensive analysis of how bias mitigation affects environmental and economic sustainability, aiming to highlight trade-offs for practitioners designing ML solutions. Method: We evaluate six bias mitigation algorithms by conducting 3,360 experiments across multiple configurations of four ML algorithms and datasets. From these experiments, we compute metrics for social, environmental, and economic sustainability, evaluating them using statistical analysis. Results: Our quantitative findings show that all bias mitigation algorithms affect the three sustainability dimensions differently, indicating that applying these algorithms involves complex trade-offs. Furthermore, we expand our discussion with qualitative insights that arise from our results, also providing implications for both research and practice.
Conclusions: Our study emphasizes the need for a deeper investigation into the trade-offs bias mitigation algorithms introduce and how they impact various non-functional requirements of ML systems.",Elsevier's Journal of Systems and Software (JSS),2025,journal,12/04/2025
Using Large Language Models to Support Software Engineering Documentation in Waterfall Life Cycles: Are We There Yet?,"Antonio Della Porta, Vincenzo De Martino, Gilberto Recupito, Carmine Iemmino, Gemma Catolino, Dario Di Nucci, Fabio Palomba",assets/docs/workshop/w1.pdf,"Software documentation is key for producing high-quality projects and ensuring their smooth evolution. Nonetheless, the activity of writing software artifacts is time-consuming and effort-prone. Looking at the existing body of knowledge, we outline limited evidence of how automated approaches may support practitioners when documenting the artifacts produced throughout the software lifecycle. In particular, there is still a lack of investigations into the capabilities of Large Language Models (LLMs), which are indeed supposed to be highly beneficial in this respect. In this paper, we propose a preliminary case study to understand how LLMs can support the development of the documentation of projects developed through a Waterfall lifecycle. Using ChatGPT, we engineered specific prompts to generate and validate the artifacts produced, taking an existing, documented software engineering project as an oracle. The main findings of the study show the ability of ChatGPT to produce most artifacts correctly. In addition, we find that software engineers would require a relatively low effort to adapt the outputs provided by ChatGPT to their own context, especially for textual artifacts.","Proceedings of the Ital-IA Intelligenza Artificiale-Thematic Workshops co-located with the 4th CINI National Lab AIIS Conference on Artificial Intelligence (Ital-IA), Naples, Italy",2024,workshop,30/04/2024
QualAI: Continuous Quality Improvement of AI-based Systems,"Nicole Novielli, Rocco Oliveto, Fabio Palomba, Fabio Calefato, Giuseppe Colavito, Vincenzo De Martino, Antonio Della Porta, Giammaria Giordano, Emanuela Guglielmi, Filippo Lanubile, Luigi Quaranta, Gilberto Recupito, Simone Scalabrino, Angelica Spina and Antonio Vitale",assets/docs/workshop/w2.pdf,"QualAI is a two-year project that aims to define a set of recommenders to continuously monitor, assess, and improve the quality of AI-based systems, with a particular focus on ML-based systems. Quality assurance will be guaranteed from different perspectives and during both the development and operations phases. We will define recommenders for the quality assurance of both data and ML models to enable practitioners to mitigate technical debt. Emphasis will be given to communication issues that could arise in hybrid teams including data scientists and software developers. In this paper, we present the project outline, provide an executive summary of the research activities, and present the expected project results.","18th Research Challenges in Information Science (RCIS) Workshop, Guimarães, Portugal",2024,workshop,01/05/2024
Continuous Quality Improvement of AI-based Systems: the QualAI Project,"Nicole Novielli, Rocco Oliveto, Fabio Palomba, Fabio Calefato, Giuseppe Colavito, Vincenzo De Martino, Antonio Della Porta, Giammaria Giordano, Emanuela Guglielmi, Filippo Lanubile, Luigi Quaranta, Gilberto Recupito, Simone Scalabrino, Angelica Spina and Antonio Vitale",assets/docs/conference/c2.pdf,"QualAI is a two-year project aimed at defining a set of recommenders to continuously monitor, assess, and improve the quality of AI-based systems, with a particular focus on machine learning (ML) applications. We will develop recommenders for the quality assurance of both data and ML models to enable practitioners to mitigate technical debt. Special attention will be paid to communication challenges that may arise in hybrid teams comprising data scientists and software developers. This paper presents the project outline, provides an executive summary of the research activities, outlines the expected project outcomes, and reports the results obtained to date."," 19th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEIW), Barcelona, Spain",2024,conference,01/09/2024